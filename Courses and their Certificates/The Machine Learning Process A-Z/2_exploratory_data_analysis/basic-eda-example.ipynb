{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for \"The Machine Learning Process Course on 365 Data Science\". \n",
    "We are analyzing real data from my YouTube channel. The focus of EDA is to understand patterns in the data so that we can start generating insights and predictions. In this notebook, I walk through the main EDA concepts from the machine learning process course. We cover:\n",
    "- Single Variable Plots\n",
    " - Histograms \n",
    " - Box Plots\n",
    " - Bar charts\n",
    "- Relationships & Multi-variable plots \n",
    " - Scatterplots\n",
    " - Correlation Matrices \n",
    " - Pivot Tables \n",
    " - Bar Charts \n",
    " - Line Charts\n",
    " \n",
    " \n",
    " I will be using matplotlib and Seaborn to visualize this data. It should be noted that there are plenty of different visualization libraries to choose from. I personally use plotly quite a lot in my own personal projects. I find that these two that we are using have good basics that are easy to understand and build on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data\n",
    "Our first step is to load in the data and get a feel for what we will be working with. We do the following steps before we start with the true EDA:\n",
    "1) Load in our libraries that we plan to use for data manipulation and visualization \n",
    "\n",
    "2) Load in our data \n",
    "\n",
    "3) Explore the high level features of our data (size, columns, etc.)\n",
    "\n",
    "4) Additional cleaning of our data if needed \n",
    "\n",
    "5) Explore high level descriptive statistics of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import basic visualization libraries \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns  \n",
    "#clean columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/ken-jee-youtube-data/Aggregated_Metrics_By_Video.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#read in data \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_agg \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/ken-jee-youtube-data/Aggregated_Metrics_By_Video.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df_agg_country_sub \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/ken-jee-youtube-data/Aggregated_Metrics_By_Country_And_Subscriber_Status.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df_ts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/ken-jee-youtube-data/Video_Performance_Over_Time.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/ken-jee-youtube-data/Aggregated_Metrics_By_Video.csv'"
     ]
    }
   ],
   "source": [
    "#read in data \n",
    "df_agg = pd.read_csv('/kaggle/input/ken-jee-youtube-data/Aggregated_Metrics_By_Video.csv',encoding='utf-8')\n",
    "df_agg_country_sub = pd.read_csv('/kaggle/input/ken-jee-youtube-data/Aggregated_Metrics_By_Country_And_Subscriber_Status.csv', encoding='utf-8')\n",
    "df_ts = pd.read_csv('/kaggle/input/ken-jee-youtube-data/Video_Performance_Over_Time.csv', encoding='utf-8')\n",
    "df_comments = pd.read_csv('/kaggle/input/ken-jee-youtube-data/All_Comments_Final.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:57.863196Z",
     "iopub.status.busy": "2022-08-31T20:16:57.862935Z",
     "iopub.status.idle": "2022-08-31T20:16:57.870240Z",
     "shell.execute_reply": "2022-08-31T20:16:57.869548Z",
     "shell.execute_reply.started": "2022-08-31T20:16:57.863165Z"
    }
   },
   "outputs": [],
   "source": [
    "#look at columns for each dataframe \n",
    "print(df_agg.columns)\n",
    "print(df_agg_country_sub.columns)\n",
    "print(df_ts.columns)\n",
    "print(df_comments.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:57.873064Z",
     "iopub.status.busy": "2022-08-31T20:16:57.872149Z",
     "iopub.status.idle": "2022-08-31T20:16:57.887802Z",
     "shell.execute_reply": "2022-08-31T20:16:57.886488Z",
     "shell.execute_reply.started": "2022-08-31T20:16:57.873018Z"
    }
   },
   "outputs": [],
   "source": [
    "#the column headers have some extra non-ascii characters, we need to clean them up before we do our analysis\n",
    "#this goes through each column and removes all the non-ascii characters \n",
    "\n",
    "newcols =[x.encode(\"ascii\", \"ignore\").decode('utf-8') for x in df_agg.columns]\n",
    "df_agg.columns = newcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:57.890078Z",
     "iopub.status.busy": "2022-08-31T20:16:57.889633Z",
     "iopub.status.idle": "2022-08-31T20:16:57.904092Z",
     "shell.execute_reply": "2022-08-31T20:16:57.903321Z",
     "shell.execute_reply.started": "2022-08-31T20:16:57.889962Z"
    }
   },
   "outputs": [],
   "source": [
    "df_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:57.905627Z",
     "iopub.status.busy": "2022-08-31T20:16:57.905244Z",
     "iopub.status.idle": "2022-08-31T20:16:57.985447Z",
     "shell.execute_reply": "2022-08-31T20:16:57.984486Z",
     "shell.execute_reply.started": "2022-08-31T20:16:57.905595Z"
    }
   },
   "outputs": [],
   "source": [
    "#Using .describe() gives us basic descriptive statistics for all of our numeric data. From this we can see which variables we might want to explore more. \n",
    "#We can see things like: which variables might have outliers, which might have skew, or which have a wide range of values\n",
    "df_agg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single variable plots\n",
    "After looking at the descriptive statistics, we may want to explore our numeric features more. To do this, we like to use single variable plots. These can help us understand the distributions of our data. If our data doesn't follow a normal distribution, we may want to make some transform it so it can be used by specific types of models like linear regresison. \n",
    "\n",
    "Looking at these charts can also help us to evaluate if there are outliers present in our data. \n",
    "\n",
    "First, we will look at histograms of our data. These help us to see skew as well as some outliers. I usually do this with every feature (if possible). Try more of these on your own! \n",
    "\n",
    "Next, we will explore some box plots to see if they tell us additional information\n",
    "\n",
    "Finally, we will explore some distribution plots for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:57.987821Z",
     "iopub.status.busy": "2022-08-31T20:16:57.986943Z",
     "iopub.status.idle": "2022-08-31T20:16:58.449993Z",
     "shell.execute_reply": "2022-08-31T20:16:58.449218Z",
     "shell.execute_reply.started": "2022-08-31T20:16:57.987780Z"
    }
   },
   "outputs": [],
   "source": [
    "#you can easily see the distribuiton of data in a column with panda's built in .hist() method. Here is the distribution for likes. There is clearly one sample that has way more like sthan the others, this is something we could look into more\n",
    "\n",
    "df_agg.Likes.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:58.451424Z",
     "iopub.status.busy": "2022-08-31T20:16:58.451185Z",
     "iopub.status.idle": "2022-08-31T20:16:58.684857Z",
     "shell.execute_reply": "2022-08-31T20:16:58.683904Z",
     "shell.execute_reply.started": "2022-08-31T20:16:58.451382Z"
    }
   },
   "outputs": [],
   "source": [
    "#let's look at the same thing for average percentage viewed. This will have no outliers unlike the likes column. We are using matplotlib's hist function here instead of the integration through pandas. \n",
    "plt.hist(df_agg['Average percentage viewed (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:58.686659Z",
     "iopub.status.busy": "2022-08-31T20:16:58.686431Z",
     "iopub.status.idle": "2022-08-31T20:16:58.936008Z",
     "shell.execute_reply": "2022-08-31T20:16:58.934821Z",
     "shell.execute_reply.started": "2022-08-31T20:16:58.686631Z"
    }
   },
   "outputs": [],
   "source": [
    "#this data has a significant amount of right skew, we may want to transform this data if we were planning to use linear regression.\n",
    "df_agg['Impressions click-through rate (%)'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:58.938818Z",
     "iopub.status.busy": "2022-08-31T20:16:58.938572Z",
     "iopub.status.idle": "2022-08-31T20:16:59.057465Z",
     "shell.execute_reply": "2022-08-31T20:16:59.056718Z",
     "shell.execute_reply.started": "2022-08-31T20:16:58.938781Z"
    }
   },
   "outputs": [],
   "source": [
    "#From this boxplot, we can see that there are quite a few outliers from our normal data. What does this tell us about the nature of likes on videos? Perhaps we shouldn't be trusting averages if something can skew so high. \n",
    "plt.boxplot(df_agg['Likes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:59.059535Z",
     "iopub.status.busy": "2022-08-31T20:16:59.059000Z",
     "iopub.status.idle": "2022-08-31T20:16:59.269890Z",
     "shell.execute_reply": "2022-08-31T20:16:59.269165Z",
     "shell.execute_reply.started": "2022-08-31T20:16:59.059480Z"
    }
   },
   "outputs": [],
   "source": [
    "#this plot looks a lot more normal. We can se emost of the videos are viewed between 25-45% of the way through. We still have some outliers, what may be special or different about those? \n",
    "plt.boxplot(df_agg['Average percentage viewed (%)'])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:59.272079Z",
     "iopub.status.busy": "2022-08-31T20:16:59.271502Z",
     "iopub.status.idle": "2022-08-31T20:16:59.466033Z",
     "shell.execute_reply": "2022-08-31T20:16:59.465321Z",
     "shell.execute_reply.started": "2022-08-31T20:16:59.272018Z"
    }
   },
   "outputs": [],
   "source": [
    "#with click through rate, we also see quite a few high outliers versus the median of / interquartile range.\n",
    "plt.boxplot(df_agg['Impressions click-through rate (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:59.467789Z",
     "iopub.status.busy": "2022-08-31T20:16:59.467331Z",
     "iopub.status.idle": "2022-08-31T20:16:59.659467Z",
     "shell.execute_reply": "2022-08-31T20:16:59.658337Z",
     "shell.execute_reply.started": "2022-08-31T20:16:59.467741Z"
    }
   },
   "outputs": [],
   "source": [
    "#To show how to do this with categorical data, let's make a categorical column.\n",
    "#We can take our revenue data and make it into different categories that are relevant to me. Usually I'm interested if videos have made less than $100, \n",
    "#between $100-1000 and over $1000. \n",
    "\n",
    "#Let's quickly \"engineer these categories for ourself\"\n",
    "\n",
    "#make bins from 0-100, 100-1000, and greater than 1000\n",
    "bins = pd.IntervalIndex.from_tuples([(0, 100), (100, 1000), (1000,float(\"inf\"))])\n",
    "df_agg['rev_buckets'] = pd.cut(df_agg['Your estimated revenue (USD)'],bins)\n",
    "\n",
    "#get count of number of videos by reveune bucket\n",
    "rev_values = df_agg['rev_buckets'].value_counts()\n",
    "rev_values.plot.bar()\n",
    "\n",
    "#We can get a sense of the balance of categorical variables using a bar chart like this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationships and Multi-Variable Plots\n",
    "A big part of exploratory data analysis is seeing how mutliple variables are related. We can use multiple different types of plots to easily see these relationships. By understanding these relationships we can start to udnerstand which features may be releated or can serve to predict others. In my opinion, this is where buisiness value starts to emerge. \n",
    "\n",
    "In this part we will explore:\n",
    "\n",
    "1) Scatter plots\n",
    "\n",
    "2) Correlation Matrices \n",
    "\n",
    "3) Pivot Tables\n",
    "\n",
    "4) Bar Charts\n",
    "\n",
    "5) Line Charts\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plots\n",
    "\n",
    "We use these to see if there is a relationship between two datapoints. \n",
    "\n",
    "Let's take a look  at a few variables and see if they may be correlated. We will explore if the average percentage viewed of the video is related to the cost per milli on the video (the amount youtube makes for 1000 views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:59.661994Z",
     "iopub.status.busy": "2022-08-31T20:16:59.661134Z",
     "iopub.status.idle": "2022-08-31T20:16:59.856437Z",
     "shell.execute_reply": "2022-08-31T20:16:59.855421Z",
     "shell.execute_reply.started": "2022-08-31T20:16:59.661937Z"
    }
   },
   "outputs": [],
   "source": [
    "#create plot with matplotlib\n",
    "plt.scatter(df_agg['Average percentage viewed (%)'] ,df_agg['CPM (USD)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:16:59.858901Z",
     "iopub.status.busy": "2022-08-31T20:16:59.858650Z",
     "iopub.status.idle": "2022-08-31T20:17:00.178700Z",
     "shell.execute_reply": "2022-08-31T20:17:00.177739Z",
     "shell.execute_reply.started": "2022-08-31T20:16:59.858851Z"
    }
   },
   "outputs": [],
   "source": [
    "#let's do the same thing with seaborn so we can see a trendline. This will be easier for us to build multiple of these \n",
    "sns.regplot(x='Average percentage viewed (%)',y='CPM (USD)', data = df_agg)\n",
    "\n",
    "#as we can see there is a very little correlation between the two variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:17:00.181205Z",
     "iopub.status.busy": "2022-08-31T20:17:00.180125Z",
     "iopub.status.idle": "2022-08-31T20:17:00.599844Z",
     "shell.execute_reply": "2022-08-31T20:17:00.598694Z",
     "shell.execute_reply.started": "2022-08-31T20:17:00.181148Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let's try another. How do variables RPM and CPM match up. RPM is how much the youtuber makes for an add. Again CPM is how much youtube sells the ad for. \n",
    "sns.regplot(x='RPM (USD)',y='CPM (USD)', data = df_agg)\n",
    "\n",
    "# Here we can see a lot stronger relationship between the two rates. \n",
    "# I should probably look into that one value where YouTube is making a massive margin on my video. These are the types of insights you can find in these graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrices \n",
    "\n",
    "Scatter plots are great for comparing two variables. Often we have many different variables that we want to see relationships between. \n",
    "\n",
    "\n",
    "In this case we would use a correlation matrix. Let's do a correlation matrix for all of our value in the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:17:00.602904Z",
     "iopub.status.busy": "2022-08-31T20:17:00.602467Z",
     "iopub.status.idle": "2022-08-31T20:17:01.046091Z",
     "shell.execute_reply": "2022-08-31T20:17:01.045140Z",
     "shell.execute_reply.started": "2022-08-31T20:17:00.602856Z"
    }
   },
   "outputs": [],
   "source": [
    "#first, we get the correlations between our datapoints. We can see all the relationships that will be polotted via the pearson correlation coefficient \n",
    "corr = df_agg.corr()\n",
    "\n",
    "sns.heatmap(corr)\n",
    "\n",
    "#this looks pretty awful, let's improve it's look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:17:01.047646Z",
     "iopub.status.busy": "2022-08-31T20:17:01.047343Z",
     "iopub.status.idle": "2022-08-31T20:17:02.168695Z",
     "shell.execute_reply": "2022-08-31T20:17:02.167955Z",
     "shell.execute_reply.started": "2022-08-31T20:17:01.047610Z"
    }
   },
   "outputs": [],
   "source": [
    "#A better example (formatting used in below chart) - https://seaborn.pydata.org/examples/many_pairwise_correlations.html \n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df_agg.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle (otherwise this looks like the square we had above and is redundant)\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure \n",
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Generate a custom diverging colormap (choose colors here)\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio \n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True, annot_kws={\"fontsize\":8})\n",
    "\n",
    "#obviously many of thes variables are HIGHLY correlated. Something we may want to explore is why Average percentage viewed is negatively related to RPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pivot Tables\n",
    "Sometimes we want to cut the data and compare how variables stack up. For example we may want to see which countries have the highest view duration. We can do this easily with pivot tables. \n",
    "\n",
    "We will use the df_agg_country_sub dataset to explore this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:17:02.170700Z",
     "iopub.status.busy": "2022-08-31T20:17:02.170415Z",
     "iopub.status.idle": "2022-08-31T20:17:02.201301Z",
     "shell.execute_reply": "2022-08-31T20:17:02.200446Z",
     "shell.execute_reply.started": "2022-08-31T20:17:02.170664Z"
    }
   },
   "outputs": [],
   "source": [
    "#pivot table to explore values. A basic pivot table takes the average of these different categories we choose.\n",
    "\n",
    "pd.pivot_table(df_agg_country_sub, index = 'Country Code', values = 'Average View Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:17:02.205613Z",
     "iopub.status.busy": "2022-08-31T20:17:02.205003Z",
     "iopub.status.idle": "2022-08-31T20:17:02.242337Z",
     "shell.execute_reply": "2022-08-31T20:17:02.241357Z",
     "shell.execute_reply.started": "2022-08-31T20:17:02.205574Z"
    }
   },
   "outputs": [],
   "source": [
    "#this time, let's compare average view percentage by country code and subscriber status.\n",
    "pd.pivot_table(df_agg_country_sub, index = 'Country Code', columns = 'Is Subscribed',values = 'Average View Percentage')\n",
    "\n",
    "#we could plot this to see which countries have the biggest difference in subscribed watch time for subscribed vs not subscribed viewers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:17:02.244774Z",
     "iopub.status.busy": "2022-08-31T20:17:02.244324Z",
     "iopub.status.idle": "2022-08-31T20:17:02.433982Z",
     "shell.execute_reply": "2022-08-31T20:17:02.433304Z",
     "shell.execute_reply.started": "2022-08-31T20:17:02.244724Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let's plot a slightly simpler graph. Let's just look at if subscribers or non-subsribers watch my videos for longer\n",
    "pd.pivot_table(df_agg_country_sub, index = 'Is Subscribed', values = 'Average View Percentage').plot.bar()\n",
    "\n",
    "#it appears that subscribers to my channel watch my videos for longer than non-subscribers. This is another way that we can use a bar chart to compare multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Charts\n",
    "Often, we want to see how variables change over time. Line charts are great for this. Time is an important feature in many models! \n",
    "\n",
    "We will use the df_ts dataset for this analys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:17:02.436085Z",
     "iopub.status.busy": "2022-08-31T20:17:02.435527Z",
     "iopub.status.idle": "2022-08-31T20:17:03.139938Z",
     "shell.execute_reply": "2022-08-31T20:17:03.138455Z",
     "shell.execute_reply.started": "2022-08-31T20:17:02.436040Z"
    }
   },
   "outputs": [],
   "source": [
    "#First we need to make sure our date field is in the date time format. We do this by converting our string to datetime\n",
    "df_ts['Date'] = pd.to_datetime(df_ts['Date'])\n",
    "\n",
    "#let's look at user subscriptions removed and see if there is any trend there. We will also compare this with user likes removed to see if we can find anything interesting\n",
    "\n",
    "#first, we have to aggregate these by video. We do this with a pivot table.\n",
    "rm_x_date = pd.pivot_table(df_ts, index='Date',values = 'User Subscriptions Removed', aggfunc ='sum').reset_index()\n",
    "\n",
    "#next we visualize this data with seaborn \n",
    "sns.lineplot(data=rm_x_date,x='Date', y='User Subscriptions Removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:17:03.142062Z",
     "iopub.status.busy": "2022-08-31T20:17:03.141428Z",
     "iopub.status.idle": "2022-08-31T20:17:03.816355Z",
     "shell.execute_reply": "2022-08-31T20:17:03.815479Z",
     "shell.execute_reply.started": "2022-08-31T20:17:03.142014Z"
    }
   },
   "outputs": [],
   "source": [
    "#now let's compare this with two other related metrics, video likes removed and dislikes\n",
    "\n",
    "likes_rm_date = pd.pivot_table(df_ts, index='Date',values='Video Likes Removed', aggfunc = 'sum').reset_index()\n",
    "dislikes_date = pd.pivot_table(df_ts, index='Date',values='Video Dislikes Added', aggfunc = 'sum').reset_index()\n",
    "\n",
    "sns.lineplot(data=rm_x_date,x='Date', y='User Subscriptions Removed')\n",
    "sns.lineplot(data=likes_rm_date,x='Date', y='Video Likes Removed')\n",
    "sns.lineplot(data=dislikes_date,x='Date', y='Video Dislikes Added')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:17:22.262255Z",
     "iopub.status.busy": "2022-08-31T20:17:22.261610Z",
     "iopub.status.idle": "2022-08-31T20:17:23.234394Z",
     "shell.execute_reply": "2022-08-31T20:17:23.233477Z",
     "shell.execute_reply.started": "2022-08-31T20:17:22.262208Z"
    }
   },
   "outputs": [],
   "source": [
    "#This was a bit messy, let's compare it over months instead of days.\n",
    "df_ts['Month_Year'] = df_ts['Date'].dt.to_period('M')\n",
    "\n",
    "#create new pivot tables \n",
    "rm_x_date = pd.pivot_table(df_ts, index='Month_Year',values = 'User Subscriptions Removed', aggfunc ='sum').reset_index()\n",
    "likes_rm_date = pd.pivot_table(df_ts, index='Month_Year',values='Video Likes Removed', aggfunc = 'sum').reset_index()\n",
    "dislikes_date = pd.pivot_table(df_ts, index='Month_Year',values='Video Dislikes Added', aggfunc = 'sum').reset_index()\n",
    "\n",
    "#create 3 separate line plots with pandas built in visualization tool \n",
    "rm_x_date.plot(x='Month_Year',y='User Subscriptions Removed')\n",
    "likes_rm_date.plot(x='Month_Year',y='Video Likes Removed')\n",
    "dislikes_date.plot(x='Month_Year',y='Video Dislikes Added')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:22:45.629371Z",
     "iopub.status.busy": "2022-08-31T20:22:45.628933Z",
     "iopub.status.idle": "2022-08-31T20:22:47.287390Z",
     "shell.execute_reply": "2022-08-31T20:22:47.286218Z",
     "shell.execute_reply.started": "2022-08-31T20:22:45.629332Z"
    }
   },
   "outputs": [],
   "source": [
    "#This was a bit messy, let's compare it over months instead of days. To get everything on one graph, we need to make it so every video has the same day.\n",
    "#Just different months and years \n",
    "df_ts['Month_Year'] = df_ts['Date'].apply(lambda x: x.replace(day=1))\n",
    "\n",
    "rm_x_date = pd.pivot_table(df_ts, index='Month_Year',values = 'User Subscriptions Removed', aggfunc ='sum').reset_index()\n",
    "likes_rm_date = pd.pivot_table(df_ts, index='Month_Year',values='Video Likes Removed', aggfunc = 'sum').reset_index()\n",
    "dislikes_date = pd.pivot_table(df_ts, index='Month_Year',values='Video Dislikes Added', aggfunc = 'sum').reset_index()\n",
    "\n",
    "#create 3 line plots with seaborn all on one graph \n",
    "sns.lineplot(data=rm_x_date,x='Month_Year', y='User Subscriptions Removed', label ='Subs Removed')\n",
    "sns.lineplot(data=likes_rm_date,x='Month_Year', y='Video Likes Removed', label = 'Likes Removed')\n",
    "sns.lineplot(data=dislikes_date,x='Month_Year', y='Video Dislikes Added', label = 'Dislikes')\n",
    "\n",
    "#it seems like there is a big spike in unsubscribes and negative comments during this period. We should explore this more.\n",
    "#maybe we should divide these all by views to determine if the spike is only related to a spike in viewership as well.\n",
    "#or maybe a single video caused a lot of negative things this period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T20:21:46.496911Z",
     "iopub.status.busy": "2022-08-31T20:21:46.496591Z",
     "iopub.status.idle": "2022-08-31T20:21:48.269466Z",
     "shell.execute_reply": "2022-08-31T20:21:48.268471Z",
     "shell.execute_reply.started": "2022-08-31T20:21:46.496873Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let's normalize this by views \n",
    "\n",
    "df_ts['Month_Year'] = df_ts['Date'].apply(lambda x: x.replace(day=1))\n",
    "\n",
    "monthly_views = pd.pivot_table(df_ts, index = 'Month_Year', values = 'Views', aggfunc = 'sum')\n",
    "rm_x_date = pd.pivot_table(df_ts, index='Month_Year',values = 'User Subscriptions Removed', aggfunc ='sum') / monthly_views.values\n",
    "likes_rm_date = pd.pivot_table(df_ts, index='Month_Year',values='Video Likes Removed', aggfunc = 'sum') / monthly_views.values\n",
    "dislikes_date = pd.pivot_table(df_ts, index='Month_Year',values='Video Dislikes Added', aggfunc = 'sum') / monthly_views.values\n",
    "\n",
    "#create 3 line plots with seaborn all on one graph \n",
    "sns.lineplot(data=rm_x_date,x='Month_Year', y='User Subscriptions Removed', label ='Subs Removed')\n",
    "sns.lineplot(data=likes_rm_date,x='Month_Year', y='Video Likes Removed', label = 'Likes Removed')\n",
    "sns.lineplot(data=dislikes_date,x='Month_Year', y='Video Dislikes Added', label = 'Dislikes')\n",
    "\n",
    "#we can see that there was still a spike in the normalized metrics during the same point in the year. It is worth exploring this further! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this segment you learned the following:\n",
    "- How to analyze individual features using histograms, boxplots, and bar charts\n",
    "- How to see relationships between features using scatterplots, correlation heatmaps, bar charts, and line plots \n",
    "- How to use these charts to seek additional insight from your data and explore what relationships to dive deeper into "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn! \n",
    "### I started you off with the basics of Exploratory Data Analsys (EDA), it's your turn to add your insights to the analysis. Excited to see what you come up with!!\n",
    "I'm constantly thinking about questions like:\n",
    "- What topics get the most viewership?\n",
    "- What do are people asking for in the comments?\n",
    "- What impacts watch time and click through rate?\n",
    "- Can we predict if a title will be clickable? \n",
    "- What thumbnails are most appealing (thumbnail data available in df_agg)\n",
    "- What is different about my \"viral\" videos and normal videos\n",
    "- Who is the core audience of my channel?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
